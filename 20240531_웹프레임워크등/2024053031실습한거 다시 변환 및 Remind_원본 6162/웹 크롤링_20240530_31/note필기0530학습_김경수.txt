
데이터 마이닝( Data Mining )

어떤데이터가 쌓여있으면 전처리 전 날거 그래로 있는 것

> 복붙해서 다했습니다 x 내가 확인절차 필요

요구사항 : 클라이언트가 요청하는 사항

구현계획 : 수입을 할꺼면 1회성 or 다회성 내가 돌릴 것인가 남이 돌릴것인가
어떠한 데이터를 요구하는지 에 따라 달라진 계획을 세우는 일

데이터클리닝 작업  : 데이터 전처리 부분을 잘 보정해야한다.

모델 배포 : system

내가 수집한거를 수정하고 test해보고 다 확인하고 모델을 배포해야 한다.

------------------------------------------------------------------------------------

웹 크롤링 : 다양한 페이지를 인덱싱하는 과정 ex) 원양어선 (중국)
!= 차곡차곡 저장하는 개념과 다르다.
>> 대표적 검색 엔진을 치면 검색하면 결과가 나온다.
     엔진들은 웹 크롤링을 통해 나온다.
구글에 검색엔진이 만들어진다 > 어떤 웹사이트 종류를 보고 확인 > 보고 저장
> 그리고 크롤링 도출
url 인덱스 만 수정한다.

웹 스크래핑 : 
웹사이트의 내용을 검색후 > 내용부분에 필요한걸 저장 하는 과정
실무에서는 스크래핑도 크롤링이라고 한다. > 검색엔진을 만드는 사람은 없기때문에...(이미 구글 네이버 등)


웹크롤링 (웹스크래핑)
파싱Parsing : 문서파일이 있을때 구조를 파악하고 데이터를 추출할 수 있도록 정리하는 작업.
복붙 작업과 다르다.
파이썬 웹 크롤링 패키지 : 
Selenium 웹크롤링 패키지는 아니다.
	어떤 웹사이트를 테스트하는 패키지 ( 어디어디클릭하는 자동화 하는 작업 - 동적 )
BeautifulSoup: 웹사이트(HTML)를 보기 좋게 파싱하는 작업(패키지)
	ex) 내가 웹사이트를 접속 할때 ~~

동적 VS 정적웹사이트 
동적 - 상호작용을 할수있다 VS 정해진 정보만 일방적으로 보여준다 - 정적
요새는 정적웹사이트는 거의 없다.

실습 - 구글 스콜라 크롤링
Selenium 이용해서 네이버지도
웹지도는 동적웹사이트

실습페이지
https://view.asiae.co.kr/article/2023032217473512545
같은페이진데 광고가 없음
https://core.asiae.co.kr/article/2023032217473512545

애드블락 Adblock 을 깔고 페이지를 보는 걸 추천 한다.

Ap 에서 pip install newspaper3k 설치후 newspaper 패키지를 사용 가능.

실습------------------------------------------------------------------------------------
소제목h3? h5? 문단 p 

모질라mozilla : 웹표준 기준의 정석이다.

언어를 표현할때 규격이 있다. 
ex) markdown 앞에만 적는 
     markup 액셀 기준 ( 화살가로 등의 규격화 된 style )

---------------------------------------------------------------------------------------

HTML

HTML 필요할때 마다 검색하는 사이트
https://developer.mozilla.org/ko/docs/Web/HTML

대소문자 구분안한다 p태그 쓸때 대문자도 됨.

p 문단 > 대문자는 상관없이 된다.

img 의 속성들
alt : 이미지를 가르킬때 사용하는 alt 정보를 참조해서 이미지나 위에 글을 읽어주거나 하는 속성


포함(내포:內包)된 요소(Nesting elements) > 위즈위그

a 태그 안에 속성
href 어디로 이동할것인가 

-----------------------------------------------------------------------------------------------

온라인 구성물 크롤링 
ex) 알라딘(도서) 구글스콜라 > 에듀테크논문 검색하면 > 본문~저장 etc등

for문 이중으로 돌렸는데 단일방법으로 할 수도 있다.







